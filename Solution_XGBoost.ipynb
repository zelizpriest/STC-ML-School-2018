{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load previously prepared data\n",
    "# unzip archive from repository\n",
    "# or use feature extraction notebook for initial *.wav data set\n",
    "full = pd.read_csv('full_set_prepared.csv')\n",
    "ans = pd.read_table('meta.txt', header = None)\n",
    "full['answers'] = [ans[ans[0] == i][4].values.tolist()[0] for i in full['0'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare test and hide sets\n",
    "test = pd.read_csv('test_set_prepared.csv')\n",
    "unknown_list = [i for i in test['0'] if i.startswith('unknown')]\n",
    "\n",
    "test_feature = test[~test['0'].isin(unknown_list)].drop('0', axis=1)\n",
    "test_answers = [i.split('_')[0] for i in test['0'] if not i.startswith('unknown')]\n",
    "test_answers = [i+'_door' if i.startswith('knock') else i for i in test_answers]\n",
    "test_target = pd.Series(test_answers)\n",
    "\n",
    "hide_feature = test[test['0'].isin(unknown_list)].drop('0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate train into features and target\n",
    "train_feature = full.drop(['answers', '0'], axis = 1)\n",
    "train_target = full['answers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#prepare train features\n",
    "scaler = StandardScaler()\n",
    "train_feature = np.delete(scaler.fit_transform(train_feature), 181, 1)\n",
    "\n",
    "#prepare test features\n",
    "test_feature = np.delete(scaler.transform(test_feature), 181, 1)\n",
    "\n",
    "#prepare hide features\n",
    "hide_feature = np.delete(scaler.transform(hide_feature), 181, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_feature, train_target, stratify = train_target,\n",
    "                                                    test_size = 0.1, random_state = 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=1000,\n",
       "       n_jobs=-1, nthread=None, objective='multi:softprob',\n",
       "       random_state=17, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=0.7)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = XGBClassifier(n_estimators=1000, subsample=0.7, n_jobs=-1, random_state=17)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "prediction = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on the train set part 0.996\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(y_test, prediction)\n",
    "print('accuracy on the train set part %.3f'%acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=1000,\n",
       "       n_jobs=-1, nthread=None, objective='multi:softprob',\n",
       "       random_state=17, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=0.7)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(train_feature, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "d:\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# predict test and hide parts\n",
    "\n",
    "test_prediction_proba = clf.predict_proba(test_feature)\n",
    "hide_prediction_proba = clf.predict_proba(hide_feature)\n",
    "full_prediction_proba = np.vstack([test_prediction_proba, hide_prediction_proba])\n",
    "\n",
    "test_prediction = clf.predict(test_feature)\n",
    "hide_prediction = clf.predict(hide_feature)\n",
    "full_prediction = np.hstack([test_prediction, hide_prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on the test part 0.943\n"
     ]
    }
   ],
   "source": [
    "print('accuracy on the test part %.3f'%accuracy_score(test_target, test_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save test part results\n",
    "ans_df = pd.DataFrame(np.hstack([np.array([i for i in test['0'] if not i.startswith('unk')]).reshape(-1, 1),\n",
    "                                 np.array([[np.max(i)] for i in test_prediction_proba]),\n",
    "                                test_prediction.reshape(-1, 1)]),\n",
    "                     columns = ['File', 'Proba', 'Class'])\n",
    "ans_df.to_csv('test_result.txt', sep = '\\t', index = None, header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save test part results\n",
    "ans_df = pd.DataFrame(np.hstack([np.array([i for i in test['0'] if i.startswith('unk')]).reshape(-1, 1),\n",
    "                                 np.array([[np.max(i)] for i in hide_prediction_proba]),\n",
    "                                hide_prediction.reshape(-1, 1)]),\n",
    "                     columns = ['File', 'Proba', 'Class'])\n",
    "ans_df.to_csv('hide_result.txt', sep = '\\t', index = None, header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save full /test directory prediction\n",
    "ans_df = pd.DataFrame(np.hstack([test['0'].values.reshape(-1, 1),\n",
    "                                 np.array([[np.max(i)] for i in full_prediction_proba]),\n",
    "                                full_prediction.reshape(-1, 1)]),\n",
    "                     columns = ['File', 'Proba', 'Class'])\n",
    "ans_df.to_csv('result.txt', sep = '\\t', index = None, header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
